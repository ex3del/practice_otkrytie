{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a197cc5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05d51420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T14:42:03.327471500Z",
     "start_time": "2023-07-11T14:42:03.318703300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from python_environment_check import check_packages\n",
    "\n",
    "\n",
    "# d = {\n",
    "#     'pandas': '1.3.2',\n",
    "#     'torch': '1.9.0',\n",
    "#     'torchtext': '0.11.0',\n",
    "#     'datasets': '1.11.0',\n",
    "#     'transformers': '4.9.1',\n",
    "# }\n",
    "# check_packages(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8cc4754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T14:42:03.747105200Z",
     "start_time": "2023-07-11T14:42:03.717032Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880c8437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T09:33:49.495732400Z",
     "start_time": "2023-07-12T09:33:49.482176200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841ee2c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:25.466903300Z",
     "start_time": "2023-07-12T10:30:24.003324Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#import torchtext\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# import transformers\n",
    "from transformers import DistilBertTokenizerFast, BertTokenizer, AutoTokenizer\n",
    "from transformers import DistilBertForSequenceClassification, BertForSequenceClassification, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d978af34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:27.114529500Z",
     "start_time": "2023-07-12T10:30:27.081551100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = \"cpu\"\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:27.817079100Z",
     "start_time": "2023-07-12T10:30:27.802001900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1c005e",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:29.639705400Z",
     "start_time": "2023-07-12T10:30:29.532013800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review  \\\n0  The existing volumetric gain for robotic explo...   \n1  Combination therapies have become the standard...   \n2  Federated learning (FL) is a privacy-aware dat...   \n3  We propose V-Doc, a question-answering tool us...   \n4  HC4 is a new suite of test collections for ad ...   \n\n                                    sentiment  \n0                                     Robotic  \n1                                      Expert  \n2                              Cyber Security  \n3                                      Expert  \n4  Information Retrieval, Recommender Systems  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The existing volumetric gain for robotic explo...</td>\n      <td>Robotic</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Combination therapies have become the standard...</td>\n      <td>Expert</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Federated learning (FL) is a privacy-aware dat...</td>\n      <td>Cyber Security</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We propose V-Doc, a question-answering tool us...</td>\n      <td>Expert</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HC4 is a new suite of test collections for ad ...</td>\n      <td>Information Retrieval, Recommender Systems</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "df = pd.read_csv('selection_main.csv', usecols=['abstract', 'class'])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.columns = ['review', 'sentiment']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fef71da",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:30.734369500Z",
     "start_time": "2023-07-12T10:30:30.728374Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Robotic                                       1000\nExpert                                        1000\nCyber Security                                1000\nInformation Retrieval, Recommender Systems    1000\nText Mining                                   1000\nControl Systems                               1000\nFuzzy                                         1000\nComputer Vision                               1000\nDatabase                                      1000\nNeural Nets                                   1000\nName: sentiment, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb7f57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:32.110598800Z",
     "start_time": "2023-07-12T10:30:32.104603Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Robotic', 'Expert', 'Cyber Security',\n       'Information Retrieval, Recommender Systems', 'Text Mining',\n       'Control Systems', 'Fuzzy', 'Computer Vision', 'Database',\n       'Neural Nets'], dtype=object)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffef58e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:38.634944100Z",
     "start_time": "2023-07-12T10:30:38.615202900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0deca072",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:39.310266800Z",
     "start_time": "2023-07-12T10:30:39.292203500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc84dd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:39.783896400Z",
     "start_time": "2023-07-12T10:30:39.750254100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LabelEncoder()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf67c2cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:40.390584300Z",
     "start_time": "2023-07-12T10:30:40.319130600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([8, 4, 2, ..., 0, 7, 5])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76ebf30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:41.143977Z",
     "start_time": "2023-07-12T10:30:41.127644800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Robotic                                       1000\nExpert                                        1000\nCyber Security                                1000\nInformation Retrieval, Recommender Systems    1000\nText Mining                                   1000\nControl Systems                               1000\nFuzzy                                         1000\nComputer Vision                               1000\nDatabase                                      1000\nNeural Nets                                   1000\nName: sentiment, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb027e5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:42.100964600Z",
     "start_time": "2023-07-12T10:30:42.081970100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['sentiment'] = le.transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "755e795c",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:42.587927700Z",
     "start_time": "2023-07-12T10:30:42.555328300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "8    1000\n4    1000\n2    1000\n6    1000\n9    1000\n1    1000\n5    1000\n0    1000\n3    1000\n7    1000\nName: sentiment, dtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a331d743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:43.469369400Z",
     "start_time": "2023-07-12T10:30:43.453172600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6a1eaee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:44.399126Z",
     "start_time": "2023-07-12T10:30:44.356959800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review  sentiment\n0  The existing volumetric gain for robotic explo...          8\n1  Combination therapies have become the standard...          4\n2  Federated learning (FL) is a privacy-aware dat...          2\n3  We propose V-Doc, a question-answering tool us...          4\n4  HC4 is a new suite of test collections for ad ...          6",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The existing volumetric gain for robotic explo...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Combination therapies have become the standard...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Federated learning (FL) is a privacy-aware dat...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We propose V-Doc, a question-answering tool us...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HC4 is a new suite of test collections for ad ...</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d2ea84e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T10:29:43.250097200Z",
     "start_time": "2023-07-12T10:29:43.218819800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# text = df['review'].astype('str')\n",
    "# labels = df['sentiment'].astype(int)\n",
    "# train_texts, test_texts, train_labels, test_labels =\\\n",
    "# train_test_split(text, labels, train_size=0.5, stratify=labels)\n",
    "\n",
    "train_texts = df.iloc[:7000]['review'].values\n",
    "train_labels = df.iloc[:7000]['sentiment'].values\n",
    "\n",
    "valid_texts = df.iloc[7000:8000]['review'].values\n",
    "valid_labels = df.iloc[7000:8000]['sentiment'].values\n",
    "\n",
    "test_texts = df.iloc[8000:]['review'].values\n",
    "test_labels = df.iloc[8000:]['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RRRRRRRRRRR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 review  sentiment\n0     The existing volumetric gain for robotic explo...          8\n1     Combination therapies have become the standard...          4\n2     Federated learning (FL) is a privacy-aware dat...          2\n3     We propose V-Doc, a question-answering tool us...          4\n4     HC4 is a new suite of test collections for ad ...          6\n...                                                 ...        ...\n9995  Stock market prediction has been an active are...          2\n9996  Closed-loop reservoir management (CLRM), in wh...          1\n9997  While language tasks are naturally expressed i...          0\n9998  We present the efficient implementations of pr...          7\n9999  Fuzzy Rule Interpolation (FRI) methods can ser...          5\n\n[10000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The existing volumetric gain for robotic explo...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Combination therapies have become the standard...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Federated learning (FL) is a privacy-aware dat...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We propose V-Doc, a question-answering tool us...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HC4 is a new suite of test collections for ad ...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>Stock market prediction has been an active are...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>Closed-loop reservoir management (CLRM), in wh...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>While language tasks are naturally expressed i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>We present the efficient implementations of pr...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>Fuzzy Rule Interpolation (FRI) methods can ser...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:46.550369100Z",
     "start_time": "2023-07-12T10:30:46.534371100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['The existing volumetric gain for robotic exploration is calculated in the 3D occupancy map, while the sampling-based exploration method is extended in the reachable (free) space. The inconsistency between them makes the existing calculation of volumetric gain inappropriate for a complete exploration of the environment. To address this issue, we propose a concave-hull based volumetric gain in a sampling-based exploration framework. The concave hull is constructed based on the viewpoints generated by Rapidly-exploring Random Tree (RRT) and the nodes that fail to expand. All space outside this concave hull is considered unknown. The volumetric gain is calculated based on the viewpoints configuration rather than using the occupancy map. With the new volumetric gain, robots can avoid inefficient or even erroneous exploration behavior caused by the inappropriateness of existing volumetric gain calculation methods. Our exploration method is evaluated against the existing state-of-the-art RRT-based method in a benchmark environment. In the evaluated environment, the average running time of our method is about 38.4% of the existing state-of-the-art method and our method is more robust.',\n       'Combination therapies have become the standard of care for diseases such as cancer, tuberculosis, malaria and HIV. However, the combinatorial set of available multi-drug treatments creates a challenge in identifying effective combination therapies available in a situation. To assist medical professionals in identifying beneficial drug-combinations, we construct an expert-annotated dataset for extracting information about the efficacy of drug combinations from the scientific literature. Beyond its practical utility, the dataset also presents a unique NLP challenge, as the first relation extraction dataset consisting of variable-length relations. Furthermore, the relations in this dataset predominantly require language understanding beyond the sentence level, adding to the challenge of this task. We provide a promising baseline model and identify clear areas for further improvement. We release our dataset, code, and baseline models publicly to encourage the NLP community to participate in this task.',\n       \"Federated learning (FL) is a privacy-aware data mining strategy keeping the private data on the owners' machine and thereby confidential. The clients compute local models and send them to an aggregator which computes a global model. In hybrid FL, the local parameters are additionally masked using secure aggregation, such that only the global aggregated statistics become available in clear text, not the client specific updates. Federated QR decomposition has not been studied extensively in the context of cross-silo federated learning. In this article, we investigate the suitability of three QR decomposition algorithms for cross-silo FL and suggest a privacy-aware QR decomposition scheme based on the Gram-Schmidt algorithm which does not blatantly leak raw data. We apply the algorithm to compute linear regression in a federated manner.\",\n       ...,\n       'While language tasks are naturally expressed in a single, unified, modeling framework, i.e., generating sequences of tokens, this has not been the case in computer vision. As a result, there is a proliferation of distinct architectures and loss functions for different vision tasks. In this work we show that a diverse set of \"core\" computer vision tasks can also be unified if formulated in terms of a shared pixel-to-sequence interface. We focus on four tasks, namely, object detection, instance segmentation, keypoint detection, and image captioning, all with diverse types of outputs, e.g., bounding boxes or dense masks. Despite that, by formulating the output of each task as a sequence of discrete tokens with a unified interface, we show that one can train a neural network with a single model architecture and loss function on all these tasks, with no task-specific customization. To solve a specific task, we use a short prompt as task description, and the sequence output adapts to the prompt so it can produce task-specific output. We show that such a model can achieve competitive performance compared to well-established task-specific models.',\n       'We present the efficient implementations of probabilistic deterministic finite automaton learning methods available in FlexFringe. These implement well-known strategies for state-merging including several modifications to improve their performance in practice. We show experimentally that these algorithms obtain competitive results and significant improvements over a default implementation. We also demonstrate how to use FlexFringe to learn interpretable models from software logs and use these for anomaly detection. Although less interpretable, we show that learning smaller more convoluted models improves the performance of FlexFringe on anomaly detection, outperforming an existing solution based on neural nets.',\n       'Fuzzy Rule Interpolation (FRI) methods can serve deducible (interpolated) conclusions even in case if some situations are not explicitly defined in a fuzzy rule based knowledge representation. This property can be beneficial in partial heuristically solved applications; there the efficiency of expert knowledge representation is mixed with the precision of machine learning methods. The goal of this paper is to introduce the benefits of FRI in the Intrusion Detection Systems (IDS) application area, in the design and implementation of the detection mechanism for Distributed Denial of Service (DDOS) attacks. In the example of the paper as a test-bed environment an open source DDOS dataset and the General Public License (GNU) FRI Toolbox was applied. The performance of the FRI-IDS example application is compared to other common classification algorithms used for detecting DDOS attacks on the same open source test-bed environment. According to the results, the overall detection rate of the FRI-IDS is in pair with other methods. On the example dataset it outperforms the detection rate of the support vector machine algorithm, whereas other algorithms (neural network, random forest and decision tree) recorded lightly higher detection rate. Consequently, the FRI inference system could be a suitable approach to be implemented as a detection mechanism for IDS; it effectively decreases the false positive rate value. Moreover, because of its fuzzy rule base knowledge representation nature, it can easily adapt expert knowledge, and also be-suitable for predicting the level of degree for threat possibility.'],\n      dtype=object)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review.values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:47.976533500Z",
     "start_time": "2023-07-12T10:30:47.957037200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\777\\AppData\\Local\\Temp\\ipykernel_26328\\1131734440.py:10: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.core.display import HTML, display"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:48.902442900Z",
     "start_time": "2023-07-12T10:30:48.794893700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "list_df = []\n",
    "for index, row in df.iterrows():\n",
    "    x = list()\n",
    "    x.append(row['sentiment'])\n",
    "    x.append(row['review'])\n",
    "    x = tuple(x)\n",
    "    list_df.append(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:49.829926800Z",
     "start_time": "2023-07-12T10:30:49.636122400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "10000"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:50.841049800Z",
     "start_time": "2023-07-12T10:30:50.835018100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(8,\n 'The existing volumetric gain for robotic exploration is calculated in the 3D occupancy map, while the sampling-based exploration method is extended in the reachable (free) space. The inconsistency between them makes the existing calculation of volumetric gain inappropriate for a complete exploration of the environment. To address this issue, we propose a concave-hull based volumetric gain in a sampling-based exploration framework. The concave hull is constructed based on the viewpoints generated by Rapidly-exploring Random Tree (RRT) and the nodes that fail to expand. All space outside this concave hull is considered unknown. The volumetric gain is calculated based on the viewpoints configuration rather than using the occupancy map. With the new volumetric gain, robots can avoid inefficient or even erroneous exploration behavior caused by the inappropriateness of existing volumetric gain calculation methods. Our exploration method is evaluated against the existing state-of-the-art RRT-based method in a benchmark environment. In the evaluated environment, the average running time of our method is about 38.4% of the existing state-of-the-art method and our method is more robust.')"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_df[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:51.535481200Z",
     "start_time": "2023-07-12T10:30:51.518448300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 51897\n",
      "Num of classes: 10\n"
     ]
    }
   ],
   "source": [
    "ag_train, ag_val = list_df[:7000], list_df[7000:]\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "word_counter = Counter()\n",
    "for (label, line) in list_df:\n",
    "    word_counter.update(tokenizer(line))\n",
    "voc = Vocab(word_counter)\n",
    "\n",
    "print('Vocabulary size:', len(voc))\n",
    "\n",
    "num_class = len(set(label for label, _ in ag_train))\n",
    "print('Num of classes:', num_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:53.124786300Z",
     "start_time": "2023-07-12T10:30:52.471416Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "train_iter = list_df\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:53.801161200Z",
     "start_time": "2023-07-12T10:30:53.125784800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:54.299749400Z",
     "start_time": "2023-07-12T10:30:54.272490700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "\n",
    "train_iter = list_df\n",
    "dataloader = DataLoader(\n",
    "    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:30:59.335675Z",
     "start_time": "2023-07-12T10:30:59.321153200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:31:00.326239300Z",
     "start_time": "2023-07-12T10:31:00.298501700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train_iter = list_df\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:31:01.381956900Z",
     "start_time": "2023-07-12T10:31:01.316259900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:31:02.094729900Z",
     "start_time": "2023-07-12T10:31:02.070221100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target -1 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 33\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, EPOCHS \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m     32\u001B[0m     epoch_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 33\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m     accu_val \u001B[38;5;241m=\u001B[39m evaluate(valid_dataloader)\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m total_accu \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m total_accu \u001B[38;5;241m>\u001B[39m accu_val:\n",
      "Cell \u001B[1;32mIn[28], line 13\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(dataloader)\u001B[0m\n\u001B[0;32m     11\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     12\u001B[0m predicted_label \u001B[38;5;241m=\u001B[39m model(text, offsets)\n\u001B[1;32m---> 13\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredicted_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     15\u001B[0m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;241m0.1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m-> 1174\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1175\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1176\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3027\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3028\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3029\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mIndexError\u001B[0m: Target -1 is out of bounds."
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10  # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64  # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = list_df[:7000], list_df[7000:]\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = random_split(\n",
    "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, accu_val\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:31:04.333171100Z",
     "start_time": "2023-07-12T10:31:02.844763400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(8,\n",
    " 'The existing volumetric gain for robotic exploration is calculated in the 3D occupancy map, while the sampling-based exploration method is extended in the reachable (free) space. The inconsistency between them makes the existing calculation of volumetric gain inappropriate for a complete exploration of the environment. To address this issue, we propose a concave-hull based volumetric gain in a sampling-based exploration framework. The concave hull is constructed based on the viewpoints generated by Rapidly-exploring Random Tree (RRT) and the nodes that fail to expand. All space outside this concave hull is considered unknown. The volumetric gain is calculated based on the viewpoints configuration rather than using the occupancy map. With the new volumetric gain, robots can avoid inefficient or even erroneous exploration behavior caused by the inappropriateness of existing volumetric gain calculation methods. Our exploration method is evaluated against the existing state-of-the-art RRT-based method in a benchmark environment. In the evaluated environment, the average running time of our method is about 38.4% of the existing state-of-the-art method and our method is more robust.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_label = 8  # {1: World, 2: Sports, 3: Business, 4: Sci/Tec}\n",
    "test_line = ('The existing volumetric gain for robotic exploration is calculated in the 3D occupancy map, while the sampling-based exploration method is extended in the reachable (free) space. The inconsistency between them makes the existing calculation of volumetric gain inappropriate for a complete exploration of the environment. To address this issue, we propose a concave-hull based volumetric gain in a sampling-based exploration framework. The concave hull is constructed based on the viewpoints generated by Rapidly-exploring Random Tree (RRT) and the nodes that fail to expand. All space outside this concave hull is considered unknown. The volumetric gain is calculated based on the viewpoints configuration rather than using the occupancy map. With the new volumetric gain, robots can avoid inefficient or even erroneous exploration behavior caused by the inappropriateness of existing volumetric gain calculation methods. Our exploration method is evaluated against the existing state-of-the-art RRT-based method in a benchmark environment. In the evaluated environment, the average running time of our method is about 38.4% of the existing state-of-the-art method and our method is more robust.')\n",
    "\n",
    "test_labels, test_text, test_offsets = collate_batch([(test_label, test_line)])\n",
    "\n",
    "probs = F.softmax(model(test_text, test_offsets), dim=1).squeeze(0)\n",
    "print('Prediction probability:', round(probs[test_labels[0]].item(), 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-12T10:29:52.497411900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class EmbeddingBagModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, inputs, offsets):\n",
    "        embedded = self.embedding(inputs, offsets)\n",
    "        return self.linear(embedded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:18:33.908343600Z",
     "start_time": "2023-07-12T10:18:33.895254100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def collate_batch(batch):\n",
    "    labels = torch.tensor([label - 1 for label, _ in batch])\n",
    "    text_list = [tokenizer(line) for _, line in batch]\n",
    "\n",
    "    # flatten tokens across the whole batch\n",
    "    text = torch.tensor([voc[t] for tokens in text_list for t in tokens])\n",
    "    # the offset of each example\n",
    "    offsets = torch.tensor(\n",
    "        [0] + [len(tokens) for tokens in text_list][:-1]\n",
    "    ).cumsum(dim=0)\n",
    "\n",
    "    return labels, text, offsets\n",
    "\n",
    "train_loader = DataLoader(ag_train, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(ag_val, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T10:18:34.774747200Z",
     "start_time": "2023-07-12T10:18:34.755739300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected i < index_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[54], line 47\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m59\u001B[39m)\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m---> 47\u001B[0m eb_model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[54], line 18\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(train_loader, val_loader)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, (label, text, offsets) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m     17\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 18\u001B[0m     predited_label \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffsets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     loss(predited_label, label)\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     20\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[48], line 8\u001B[0m, in \u001B[0;36mEmbeddingBagModel.forward\u001B[1;34m(self, inputs, offsets)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, offsets):\n\u001B[1;32m----> 8\u001B[0m     embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffsets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear(embedded)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:389\u001B[0m, in \u001B[0;36mEmbeddingBag.forward\u001B[1;34m(self, input, offsets, per_sample_weights)\u001B[0m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, offsets: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, per_sample_weights: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    359\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Forward pass of EmbeddingBag.\u001B[39;00m\n\u001B[0;32m    360\u001B[0m \n\u001B[0;32m    361\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;124;03m          returned vectors filled by zeros.\u001B[39;00m\n\u001B[0;32m    388\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding_bag\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[43m                           \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    391\u001B[0m \u001B[43m                           \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    392\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mper_sample_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minclude_last_offset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    393\u001B[0m \u001B[43m                           \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2392\u001B[0m, in \u001B[0;36membedding_bag\u001B[1;34m(input, weight, offsets, max_norm, norm_type, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\u001B[0m\n\u001B[0;32m   2385\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m per_sample_weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   2386\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m   2387\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding_bag: per_sample_weights was not None. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2388\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mper_sample_weights is only supported for mode=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2389\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(got mode=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m). Please open a feature request on GitHub.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(mode)\n\u001B[0;32m   2390\u001B[0m     )\n\u001B[1;32m-> 2392\u001B[0m ret, _, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding_bag\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffsets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_enum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_sample_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_last_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\n\u001B[0;32m   2394\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2395\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected i < index_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 7\n",
    "EMB_SIZE = 64\n",
    "CHECKPOINT = './models/embedding_bag_ag_news.pt'\n",
    "USE_PRETRAINED = True  # change to False if you want to retrain your own model\n",
    "\n",
    "def train_model(train_loader, val_loader):\n",
    "    model = EmbeddingBagModel(len(voc), EMB_SIZE, num_class)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        # training\n",
    "        model.train()\n",
    "        total_acc, total_count = 0, 0\n",
    "\n",
    "        for idx, (label, text, offsets) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            predited_label = model(text, offsets)\n",
    "            loss(predited_label, label).backward()\n",
    "            optimizer.step()\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "\n",
    "            if (idx + 1) % 500 == 0:\n",
    "                print('epoch {:3d} | {:5d}/{:5d} batches | accuracy {:8.3f}'.format(\n",
    "                    epoch, idx + 1, len(train_loader), total_acc / total_count\n",
    "                ))\n",
    "                total_acc, total_count = 0, 0\n",
    "\n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        total_acc, total_count = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for label, text, offsets in val_loader:\n",
    "                predited_label = model(text, offsets)\n",
    "                total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "                total_count += label.size(0)\n",
    "\n",
    "        print('-' * 59)\n",
    "        print('end of epoch {:3d} | valid accuracy {:8.3f} '.format(epoch, total_acc / total_count))\n",
    "        print('-' * 59)\n",
    "\n",
    "    torch.save(model, CHECKPOINT)\n",
    "    return model\n",
    "\n",
    "eb_model = torch.load(CHECKPOINT) if USE_PRETRAINED else train_model(train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-12T09:59:03.893153800Z",
     "start_time": "2023-07-12T09:59:03.794042600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "f361dd64",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tokenizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1b17400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:36.812805700Z",
     "start_time": "2023-07-11T15:30:36.527380800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c784b9b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:36.873857600Z",
     "start_time": "2023-07-11T15:30:36.844851400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "#                                           do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "643a56c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:37.958916300Z",
     "start_time": "2023-07-11T15:30:37.129208Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f63a0778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:37.974756900Z",
     "start_time": "2023-07-11T15:30:37.959914600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Encoding(num_tokens=476, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bb7548",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Dataset Class and Loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffa3bd9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:38.392582600Z",
     "start_time": "2023-07-11T15:30:38.375578900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "valid_dataset = IMDbDataset(valid_encodings, valid_labels)\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53f8a887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:38.404585400Z",
     "start_time": "2023-07-11T15:30:38.389582Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2fb5fe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading and fine-tuning a pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e55ec157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:39.496572100Z",
     "start_time": "2023-07-11T15:30:38.880593800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',\n",
    "                                                            num_labels=df['sentiment'].nunique(),\n",
    "                                                            output_attentions=False,\n",
    "                                                            output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b601d03b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:39.925950900Z",
     "start_time": "2023-07-11T15:30:39.911653700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "#                                                       num_labels=df['sentiment'].nunique(),\n",
    "#                                                       output_attentions=False,\n",
    "#                                                       output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8f18320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:40.833591900Z",
     "start_time": "2023-07-11T15:30:40.668865Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.to('cuda')\n",
    "model.train()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d57cc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Train Model -- Manual Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:42.051194200Z",
     "start_time": "2023-07-11T15:30:42.047951900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d164e0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:30:42.853086100Z",
     "start_time": "2023-07-11T15:30:42.842751200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct_pred, num_examples = 0, 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "        \n",
    "        ### Prepare data\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            predicted_labels = torch.argmax(logits, 1)\n",
    "            num_examples += labels.size(0)\n",
    "            correct_pred += (predicted_labels == labels).sum()\n",
    "        \n",
    "        return correct_pred.float()/num_examples * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfe8f63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:33:40.922418200Z",
     "start_time": "2023-07-11T15:30:43.648141400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/0003 | Batch 0000/0438 | Loss: 2.2791\n",
      "Epoch: 0001/0003 | Batch 0250/0438 | Loss: 0.1799\n",
      "Training accuracy: 92.01%\n",
      "Valid accuracy: 92.10%\n",
      "Time elapsed: 1.02 min\n",
      "Epoch: 0002/0003 | Batch 0000/0438 | Loss: 0.8439\n",
      "Epoch: 0002/0003 | Batch 0250/0438 | Loss: 0.0351\n",
      "Training accuracy: 97.41%\n",
      "Valid accuracy: 95.20%\n",
      "Time elapsed: 1.99 min\n",
      "Epoch: 0003/0003 | Batch 0000/0438 | Loss: 0.4293\n",
      "Epoch: 0003/0003 | Batch 0250/0438 | Loss: 0.0106\n",
      "Training accuracy: 98.13%\n",
      "Valid accuracy: 96.20%\n",
      "Time elapsed: 2.95 min\n",
      "Total Training Time: 2.95 min\n",
      "CPU times: total: 2min 32s\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        ### Prepare data\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        batch['labels'] = batch['labels'].type(torch.LongTensor)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        ### Forward\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss, logits = outputs['loss'], outputs['logits']\n",
    "        \n",
    "        ### Backward\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        ### Logging\n",
    "        if not batch_idx % 250:\n",
    "            print (f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n",
    "                   f'Batch {batch_idx:04d}/{len(train_loader):04d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "            \n",
    "    model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'Training accuracy: '\n",
    "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
    "              f'\\nValid accuracy: '\n",
    "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
    "        \n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "# print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import Lime, LimeBase\n",
    "from captum._utils.models.linear_model import SkLearnLinearRegression, SkLearnLasso\n",
    "\n",
    "import os\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T15:33:41.001532300Z",
     "start_time": "2023-07-11T15:33:40.923456500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\777\\AppData\\Local\\Temp\\ipykernel_7688\\1131734440.py:10: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.core.display import HTML, display"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T15:33:41.125578400Z",
     "start_time": "2023-07-11T15:33:41.003532800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# remove the batch dimension for the embedding-bag model\n",
    "def forward_func(text, offsets):\n",
    "    return model(text.squeeze(0), offsets)\n",
    "\n",
    "# encode text indices into latent representations & calculate cosine similarity\n",
    "def exp_embedding_cosine_distance(original_inp, perturbed_inp, _, **kwargs):\n",
    "    original_emb = model.embedding(original_inp, None)\n",
    "    perturbed_emb = model.embedding(perturbed_inp, None)\n",
    "    distance = 1 - F.cosine_similarity(original_emb, perturbed_emb, dim=1)\n",
    "    return torch.exp(-1 * (distance ** 2) / 2)\n",
    "\n",
    "# binary vector where each word is selected independently and uniformly at random\n",
    "def bernoulli_perturb(text, **kwargs):\n",
    "    probs = torch.ones_like(text) * 0.5\n",
    "    return torch.bernoulli(probs).long()\n",
    "\n",
    "# remove absenst token based on the intepretable representation sample\n",
    "def interp_to_input(interp_sample, original_input, **kwargs):\n",
    "    return original_input[interp_sample.bool()].view(original_input.size(0), -1)\n",
    "\n",
    "lasso_lime_base = LimeBase(\n",
    "    forward_func,\n",
    "    interpretable_model=SkLearnLasso(alpha=0.08),\n",
    "    similarity_func=exp_embedding_cosine_distance,\n",
    "    perturb_func=bernoulli_perturb,\n",
    "    perturb_interpretable_space=True,\n",
    "    from_interp_rep_transform=interp_to_input,\n",
    "    to_interp_rep_transform=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T15:33:41.171755900Z",
     "start_time": "2023-07-11T15:33:41.128595700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "'The existing volumetric gain for robotic exploration is calculated in the 3D occupancy map, while the sampling-based exploration method is extended in the reachable (free) space. The inconsistency between them makes the existing calculation of volumetric gain inappropriate for a complete exploration of the environment. To address this issue, we propose a concave-hull based volumetric gain in a sampling-based exploration framework. The concave hull is constructed based on the viewpoints generated by Rapidly-exploring Random Tree (RRT) and the nodes that fail to expand. All space outside this concave hull is considered unknown. The volumetric gain is calculated based on the viewpoints configuration rather than using the occupancy map. With the new volumetric gain, robots can avoid inefficient or even erroneous exploration behavior caused by the inappropriateness of existing volumetric gain calculation methods. Our exploration method is evaluated against the existing state-of-the-art RRT-based method in a benchmark environment. In the evaluated environment, the average running time of our method is about 38.4% of the existing state-of-the-art method and our method is more robust.'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T15:35:12.329342200Z",
     "start_time": "2023-07-11T15:35:12.317260400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19828\n",
      "Num of classes: 10000\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "word_counter = Counter()\n",
    "for label, line in df.iterrows():\n",
    "    word_counter.update(tokenizer(str(line)))\n",
    "voc = Vocab(word_counter)\n",
    "\n",
    "print('Vocabulary size:', len(voc))\n",
    "\n",
    "num_class = len(set(label for label, _ in df.iterrows()))\n",
    "print('Num of classes:', num_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T15:42:27.963947200Z",
     "start_time": "2023-07-11T15:42:26.579797500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    labels = torch.tensor([label - 1 for label, _ in batch])\n",
    "    text_list = [tokenizer(line) for _, line in batch]\n",
    "\n",
    "    # flatten tokens across the whole batch\n",
    "    text = torch.tensor([voc[t] for tokens in text_list for t in tokens])\n",
    "    # the offset of each example\n",
    "    offsets = torch.tensor(\n",
    "        [0] + [len(tokens) for tokens in text_list][:-1]\n",
    "    ).cumsum(dim=0)\n",
    "\n",
    "    return labels, text, offsets\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16,\n",
    "                          shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=16,\n",
    "                        shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T15:42:31.279956800Z",
     "start_time": "2023-07-11T15:42:31.268895800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (191) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m test_line \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe existing volumetric gain for robotic exploration is calculated in the 3D occupancy map, while the sampling-based exploration method is extended in the reachable (free) space. The inconsistency between them makes the existing calculation of volumetric gain inappropriate for a complete exploration of the environment. To address this issue, we propose a concave-hull based volumetric gain in a sampling-based exploration framework. The concave hull is constructed based on the viewpoints generated by Rapidly-exploring Random Tree (RRT) and the nodes that fail to expand. All space outside this concave hull is considered unknown. The volumetric gain is calculated based on the viewpoints configuration rather than using the occupancy map. With the new volumetric gain, robots can avoid inefficient or even erroneous exploration behavior caused by the inappropriateness of existing volumetric gain calculation methods. Our exploration method is evaluated against the existing state-of-the-art RRT-based method in a benchmark environment. In the evaluated environment, the average running time of our method is about 38.4\u001B[39m\u001B[38;5;132;01m% o\u001B[39;00m\u001B[38;5;124mf the existing state-of-the-art method and our method is more robust.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m test_labels, test_text, test_offsets \u001B[38;5;241m=\u001B[39m collate_batch([(test_label, test_line)])\n\u001B[1;32m----> 6\u001B[0m probs \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_text\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_offsets\u001B[49m\u001B[43m)\u001B[49m, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrediction probability:\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mround\u001B[39m(probs[test_labels[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39mitem(), \u001B[38;5;241m4\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:763\u001B[0m, in \u001B[0;36mDistilBertForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    756\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m    757\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m    758\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m    759\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m    760\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    761\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m--> 763\u001B[0m distilbert_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistilbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    764\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    765\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    766\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    767\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    768\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    769\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    770\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    771\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    772\u001B[0m hidden_state \u001B[38;5;241m=\u001B[39m distilbert_output[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# (bs, seq_len, dim)\u001B[39;00m\n\u001B[0;32m    773\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m hidden_state[:, \u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# (bs, dim)\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:581\u001B[0m, in \u001B[0;36mDistilBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    578\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[0;32m    579\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m--> 581\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[0;32m    583\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer(\n\u001B[0;32m    584\u001B[0m     x\u001B[38;5;241m=\u001B[39membeddings,\n\u001B[0;32m    585\u001B[0m     attn_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    589\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[0;32m    590\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:135\u001B[0m, in \u001B[0;36mEmbeddings.forward\u001B[1;34m(self, input_ids, input_embeds)\u001B[0m\n\u001B[0;32m    131\u001B[0m     position_ids \u001B[38;5;241m=\u001B[39m position_ids\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mexpand_as(input_ids)  \u001B[38;5;66;03m# (bs, max_seq_length)\u001B[39;00m\n\u001B[0;32m    133\u001B[0m position_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mposition_embeddings(position_ids)  \u001B[38;5;66;03m# (bs, max_seq_length, dim)\u001B[39;00m\n\u001B[1;32m--> 135\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[43minput_embeds\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mposition_embeddings\u001B[49m  \u001B[38;5;66;03m# (bs, max_seq_length, dim)\u001B[39;00m\n\u001B[0;32m    136\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(embeddings)  \u001B[38;5;66;03m# (bs, max_seq_length, dim)\u001B[39;00m\n\u001B[0;32m    137\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(embeddings)  \u001B[38;5;66;03m# (bs, max_seq_length, dim)\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (191) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "test_label = 8  # {1: World, 2: Sports, 3: Business, 4: Sci/Tec}\n",
    "test_line = ('The existing volumetric gain for robotic exploration is calculated in the 3D occupancy map, while the sampling-based exploration method is extended in the reachable (free) space. The inconsistency between them makes the existing calculation of volumetric gain inappropriate for a complete exploration of the environment. To address this issue, we propose a concave-hull based volumetric gain in a sampling-based exploration framework. The concave hull is constructed based on the viewpoints generated by Rapidly-exploring Random Tree (RRT) and the nodes that fail to expand. All space outside this concave hull is considered unknown. The volumetric gain is calculated based on the viewpoints configuration rather than using the occupancy map. With the new volumetric gain, robots can avoid inefficient or even erroneous exploration behavior caused by the inappropriateness of existing volumetric gain calculation methods. Our exploration method is evaluated against the existing state-of-the-art RRT-based method in a benchmark environment. In the evaluated environment, the average running time of our method is about 38.4% of the existing state-of-the-art method and our method is more robust.')\n",
    "\n",
    "test_labels, test_text, test_offsets = collate_batch([(test_label, test_line)])\n",
    "\n",
    "probs = F.softmax(model(test_text.to(DEVICE), test_offsets), dim=1).squeeze(0)\n",
    "print('Prediction probability:', round(probs[test_labels[0]].item(), 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T15:52:32.488371800Z",
     "start_time": "2023-07-11T15:52:32.425427600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attrs = lasso_lime_base.attribute(\n",
    "    test_text.unsqueeze(0), # add batch dimension for Captum\n",
    "    target=test_labels,\n",
    "    additional_forward_args=(test_offsets,),\n",
    "    n_samples=32000,\n",
    "    show_progress=True\n",
    ").squeeze(0)\n",
    "\n",
    "print('Attribution range:', attrs.min().item(), 'to', attrs.max().item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_text_attr(attrs):\n",
    "    rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "    alpha = lambda x: abs(x) ** 0.5\n",
    "    token_marks = [\n",
    "        f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "        for token, attr in zip(tokenizer(test_line), attrs.tolist())\n",
    "    ]\n",
    "\n",
    "    display(HTML('<p>' + ' '.join(token_marks) + '</p>'))\n",
    "\n",
    "show_text_attr(attrs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4b1eddd",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-07-11T13:20:33.552744400Z",
     "start_time": "2023-07-11T13:20:33.538201700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e81d626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T13:20:38.054719100Z",
     "start_time": "2023-07-11T13:20:33.554742100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.44 s\n",
      "Wall time: 4.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "true_labels, pred_labels = [], []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct_pred, num_examples = 0, 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs['logits']\n",
    "        predicted_labels = torch.argmax(logits, 1)\n",
    "        true_labels.append(labels.cpu().data.numpy())\n",
    "        pred_labels.append(predicted_labels.cpu().data.numpy())\n",
    "\n",
    "true_labels = np.array(true_labels).reshape(1, -1)[0]\n",
    "pred_labels = np.array(pred_labels).reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51d3f9af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T13:20:40.229961100Z",
     "start_time": "2023-07-11T13:20:40.213886500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       183\n",
      "           1       0.95      0.94      0.94       220\n",
      "           2       0.98      0.95      0.97       191\n",
      "           3       0.98      0.96      0.97       200\n",
      "           4       0.92      0.97      0.94       190\n",
      "           5       0.98      0.97      0.98       202\n",
      "           6       0.97      0.91      0.94       215\n",
      "           7       0.95      0.98      0.97       200\n",
      "           8       0.95      0.99      0.97       203\n",
      "           9       0.96      0.97      0.96       196\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38abbc5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T13:20:43.406941100Z",
     "start_time": "2023-07-11T13:20:43.373212600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                           Computer Vision       0.99      0.97      0.98       183\n",
      "                           Control Systems       0.95      0.94      0.94       220\n",
      "                            Cyber Security       0.98      0.95      0.97       191\n",
      "                                  Database       0.98      0.96      0.97       200\n",
      "                                    Expert       0.92      0.97      0.94       190\n",
      "                                     Fuzzy       0.98      0.97      0.98       202\n",
      "Information Retrieval, Recommender Systems       0.97      0.91      0.94       215\n",
      "                               Neural Nets       0.95      0.98      0.97       200\n",
      "                                   Robotic       0.95      0.99      0.97       203\n",
      "                               Text Mining       0.96      0.97      0.96       196\n",
      "\n",
      "                                  accuracy                           0.96      2000\n",
      "                                 macro avg       0.96      0.96      0.96      2000\n",
      "                              weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(le.inverse_transform(true_labels), le.inverse_transform(pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38d8b5c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T13:21:00.988590600Z",
     "start_time": "2023-07-11T13:21:00.957584500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                           Computer Vision       0.99      0.97      0.98       183\n",
      "                           Control Systems       0.95      0.94      0.94       220\n",
      "                            Cyber Security       0.98      0.95      0.97       191\n",
      "                                  Database       0.98      0.96      0.97       200\n",
      "                                    Expert       0.92      0.97      0.94       190\n",
      "                                     Fuzzy       0.98      0.97      0.98       202\n",
      "Information Retrieval, Recommender Systems       0.97      0.91      0.94       215\n",
      "                               Neural Nets       0.95      0.98      0.97       200\n",
      "                                   Robotic       0.95      0.99      0.97       203\n",
      "                               Text Mining       0.96      0.97      0.96       196\n",
      "\n",
      "                                  accuracy                           0.96      2000\n",
      "                                 macro avg       0.96      0.96      0.96      2000\n",
      "                              weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_labels, pred_labels, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd2526fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T13:44:30.965843800Z",
     "start_time": "2023-07-11T13:44:30.902422900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df97e7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b171d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fccef3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3b82f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}